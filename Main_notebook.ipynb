{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from config import HYPERPARAMS, ECONPARAMS\n",
    "from training_seq import training\n",
    "from calc_nash_monopoly import actions_dict\n",
    "from testing_seq import testing\n",
    "params = HYPERPARAMS['full_obs_NB']\n",
    "eparams = ECONPARAMS['base_case']\n",
    "# Economic parameters\n",
    "MEAN_C = 1\n",
    "MEAN_Q = 2\n",
    "A0 = 1\n",
    "MU = 1/2\n",
    "nA = params['nA']\n",
    "grid = nA # Higher values gives better approximation of nash/monopoly-profits\n",
    "# TRAINING SETUP ######################################################\n",
    "FIRMLIST = []\n",
    "diff_range = np.linspace(MEAN_Q*0.9,MEAN_Q*1.1,5)\n",
    "\n",
    "for c in [MEAN_C]:\n",
    "    for q in [MEAN_Q]:\n",
    "        q = round(q, 2)\n",
    "        FIRMLIST.append({'cost': c, 'quality': q})\n",
    "\n",
    "NASH_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST, FIRMLIST, \"nash\")\n",
    "MONOPOLY_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST, FIRMLIST, \"monopoly\")\n",
    "\n",
    "eparams = {\n",
    "        'firmlist': FIRMLIST,\n",
    "        'a0': A0,\n",
    "        'mu': MU,\n",
    "        'nash_actions': NASH_ACTIONS,\n",
    "        'monopoly_actions': MONOPOLY_ACTIONS,\n",
    "        'randomness': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING SETUP #####################################################\n",
    "FIRMLIST_expanded = []\n",
    "diff_range = np.linspace(MEAN_Q*0.9,MEAN_Q*1.1,10)\n",
    "\n",
    "for c in [MEAN_C]:\n",
    "    for q in diff_range:\n",
    "        q = round(q, 2)\n",
    "        FIRMLIST_expanded.append({'cost': c, 'quality': q})\n",
    "\n",
    "NASH_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST_expanded, FIRMLIST_expanded, \"nash\")\n",
    "MONOPOLY_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST_expanded, FIRMLIST_expanded, \"monopoly\")\n",
    "\n",
    "eparams_exp = {\n",
    "        'firmlist': FIRMLIST_expanded,\n",
    "        'a0': A0,\n",
    "        'mu': MU,\n",
    "        'nash_actions': NASH_ACTIONS,\n",
    "        'monopoly_actions': MONOPOLY_ACTIONS,\n",
    "        'randomness': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Takes a long time to run #######################################\n",
    "agent = training(params, eparams, 8)\n",
    "testing(FIRMLIST, agent, params, eparams,'seq.csv', False)\n",
    "testing(FIRMLIST_expanded, agent, params, eparams_exp,'seq_exp.csv', False)\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from dqn_model import Net\n",
    "import numpy as np\n",
    "from agent import Agent1 as Agent\n",
    "from experience_buffer import ExperienceBuffer\n",
    "from config import HYPERPARAMS\n",
    "from calc_nash_monopoly import actions_dict\n",
    "params = HYPERPARAMS['full_obs_NB']\n",
    "from cont_bertrand import ContBertrand\n",
    "\n",
    "\n",
    "REPLAY_SIZE = params['replay_size']\n",
    "nA = params['nA']\n",
    "LEARNING_RATE = params['learning_rate']\n",
    "#LEARNING_RATE = 0.001\n",
    "#nA = 7\n",
    "MEAN_C = 1\n",
    "MEAN_Q = 2\n",
    "A0 = 1\n",
    "MU = 1/2\n",
    "FIRMLIST = []\n",
    "\n",
    "for c in [MEAN_C]:\n",
    "    for q in [MEAN_Q]:\n",
    "        q = round(q, 2)\n",
    "        FIRMLIST.append({'cost': c, 'quality': q})\n",
    "NASH_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST, FIRMLIST, \"nash\")\n",
    "MONOPOLY_ACTIONS = actions_dict(nA, A0, MU, FIRMLIST, FIRMLIST, \"monopoly\")\n",
    "\n",
    "\n",
    "eparams = {\n",
    "        'firmlist': FIRMLIST,\n",
    "        'a0': A0,\n",
    "        'mu': MU,\n",
    "        'nash_actions': NASH_ACTIONS,\n",
    "        'monopoly_actions': MONOPOLY_ACTIONS,\n",
    "        'randomness': 0\n",
    "        }\n",
    "\n",
    "firm0 = FIRMLIST[0]\n",
    "firm1 = firm0\n",
    "PATH = \"3499993_0checkpoint.pt\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model = Net(2,nA,8).to('cpu')\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "model.load_state_dict(checkpoint['agent_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_dict'])\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "env = ContBertrand(firm0, firm1, eparams)\n",
    "model.eval()\n",
    "agent = Agent(env, buffer, model, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing_seq import testing\n",
    "testing(FIRMLIST, agent, params, eparams,'cheat.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
